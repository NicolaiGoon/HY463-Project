<h3>Πανεπηστίμιο Κρήτης</h3>

<h2>Τμήμα Επιστήμης Υπολογιστών</h2>

<h1>ΗΥ463 Συστήματα Ανάκτησης Πληροφοριών</h1>

<h3>Εξάμηνο: Άνοιξη 2021</h3>

<h3>Στοιχεία:</h3>

| Μέλος         | 1ο                 |
| ------------- | ------------------ |
| Ονοματεπώνυμο | Νικόλαος Γουνάκης  |
| ΑΜ            | 3932               |
| Email         | csd3932@csd.uoc.gr |

<br>
<h1>Πίνακας Περιεχομένων</h1>

- [Εισαγωγή](#εισαγωγή)
- [Διαδικασία Ευρετηρίασης](#διαδικασία-ευρετηρίασης)
  - [Διάβασμα Αρχείων](#διάβασμα-αρχείων)
    - [Tokenizing](#tokenizing)
    - [Αφαίρεση Stopwords](#αφαίρεση-stopwords)
    - [Stemming](#stemming)
  - [Ανεστραμμένο Ευρετήριο](#ανεστραμμένο-ευρετήριο)
    - [DocumentsFile](#documentsfile)
    - [PostingFile](#postingfile)
    - [VocabularyFile](#vocabularyfile)
  - [Απλό Indexing](#απλό-indexing)
  - [Partial Indexing](#partial-indexing)
  - [Αποτιμητής Ερωτήσεων](#αποτιμητής-ερωτήσεων)
- [Μετρήσεις](#μετρήσεις)
  - [Ευρετηρίαση](#ευρετηρίαση)
- [Επίλογος](#επίλογος)
- [Αναφορές](#αναφορές)

# Εισαγωγή

Το project υλοποιήθηκε σε python και για να τρέξει θα χρειαστεί να εγκαταστήσετε ότι βιβλιοθήκη περιέχει το αρχείο requirements.txt με την εντολή:<br> 
`$ pip install -r requirements.txt`. 

Γενικά υλοποιήθηκε και το απλό indexing το οποίο είναι εξερετικά γρήγορο αλλά καταναλώνει πολύ μνήμη και το partial indexing το οποίο είναι αργό χρησιμοποιέι λιγότερη μνήμη αλλα μπορεί να ευρετηριάσει μεγαλύτερες συλλογές εγγράφων.

Εφόσον το project έγινε σε διαφορετική γλώσσα απο την προτεινόμενη (java) χρειάστηκε να υλοποιήσω όλα τα δοθέντα κομμάτια κώδικα απο την αρχή.

# Διαδικασία Ευρετηρίασης

Για απλό indexing:
`$ python app.py -index`

Για partial indexing:
`$ python app.py -pindex`

Στην συνέχεια ανοίγει γραφική διεπαφή για την επιλογή φακέλου και είναι η μόνη γραφική διδεπαφη που υπάρχει προς το παρόν. Τα υπόλοιπα γίνονται μέσο του τερματικού.

## Διάβασμα Αρχείων

Εφόσον επιλέξουμε φάκελο το πρόγραμμα αρχίζει να διαβάζει αναδρομικά όλους του υπο-φακέλους και διαβάζει μόνο τα αρχεία με κατάληξη `.nxml`. Τα υπόλοιπα τα αγνοεί.

Στο αρχείο  `readxml.py` φαίνεται η υλοποίηση , όπου το πρόγραμμα διαβάζει τα  απαραίτητα tags. Στην συνέχεια περνάνε απο tokenzer και χρησιμοποιύνται για να φιαχτεί ένα document object (`Document.py`) το οποίο αναπαρηστά ένα έγγραφο. 

Αξίζει να αναφερθεί οτι κρατιέται πληροφορία σε ποία tags εμφανίζεται κάθε λέξη και πόσες φορές μέσα σε κάθε document object.

### Tokenizing

Η υλοποίηση βρίσκεται στο `tokenizer.py`. H συνάρτηση που κάνει tokenize παίρνει ως παράμετρο ένα string η έναν πίνακα απο strings και επιστρέφει έναν πίνακα με tokens όπου κάθε token αποτελείται μόνο απο αλφαριθμητικούς χαρακτήρες.

### Αφαίρεση Stopwords

Η υλοποίηση βρίσκεται πάλι στο `tokenizer.py`. Διαβάζει τα δοθέντα αρχεία `stopwordsEn.txt` και `stopwordsGr.txt` χρησιμοποιέιται απο την συνάρτηση `tokenize(s)` για να τα αφαιρεί.

### Stemming

Το stemming γίνεται μέσα στον constructor του document object (`Document.py`) κατα τον υπολογισμό συχνοτήτων των λέξεων.

Για το stemming χρησιμοποιήθηκε η βιβλιοθήκη `nltk` όπου υποστιρίζει αγγλικό stemming

## Ανεστραμμένο Ευρετήριο

Και με τις δύο τεχνικές indexing  παράγεται το ίδιο ανεστραμμένο ευρετήριο.

### DocumentsFile

Έχει τη μορφή:
`doc_id` `path` `norm`

### PostingFile

Έχει τη μορφή:
`doc_id` `tf` `appearances` `pointer to DocumentsFile`

όπου `appearances`: `{'abstract': [89, 94, 96, 98], 'body': [624, 722]}` ένα dictionary που γράφει σε ποιό σημείο μέσα tag εμφανίζεται ο όρος και απο το length του array μπορούμε να μάθουμε και πόσες φορές.  

### VocabularyFile

Έχει τη μορφή:
`term_id` `df` `pointer to PostingFile`

όπου `term_id`: το string που αναπαρηστά έναν όρο

## Απλό Indexing

1. Το πρόγραμμα ξεκινά να διαβάζει όλα τα documents απο έναν φάκελο.
2. Στην συνέχεια απο όλα τα documents κάνει extract τα terms και δημιουργεί το vocabulary
3. Έπειτα εφόσον έχει όλα τα documents και το vocabulary στην μνήμη ξεκινά να παράγει το inverted file

## Partial Indexing

1. Το πρόγραμμα ξεκινά να διαβάζει αρχεία απο έναν φάκελο
2. Όταν η μνήμη φτάσει στο 80% τότε ξεκινά να παράγει ένα partial inverted file
3. Επαναλαμβάνονται τα βήματα 1 και 2 μέχρις ότου να έχουν διαβαστεί όλα τα αρχεία του φακέλου
4. Eφόσον έχουν διαβαστεί όλα τα αρχεία του φακέλου και έχου παραχθεί όλα τα partial inverted files , τότε ξεκινάει η διαδικασία του merging όπως περιγραφεται στο δοσμένο pdf `Partial Indexing and Merging`

## Αποτιμητής Ερωτήσεων

Για να τρέξει το πρόγραμμα σε query evaluation mode το τρέχουμε χωρίς κανένα argument:
`$ python app.py`

Στην συνέχεια φορτώνεται το Vocabulary στην μνήμη και το σύστημα ρωτάει τον χρήστη να επιλέξει ανάμεσα σε:
1. diagnosis
2. test
3. treatment

Εφόσον επιλέξει τότε του δίνεται η ευκαιρία να εισάγει summary ή description.

Έπειτα εφόσον πατήσει `enter` ο χρήστης τότε γίνεται evaluation του query χρησιμοποιόντας το `Διανυσματικό Μοντέλο` και επιστρέφονται όλα τα έγγραφα τα οποία περιέχουν όρους απο το query σε αύξουσα σειρα με βάση το score.

Γενικά , δεν έχει υλοποιηθεί ακόμα κάποιος μηχανισμός για τον διαχωρισμό  των εγγράφων στις 3 παραπάνω κατηγορίες διότι παραπάνω έμφαση έδωσα στo να υλοποιήσω και τις 2 τεχνικές indexing.


# Μετρήσεις

## Ευρετηρίαση

| Method           | MiniCollection    | MedicalCollection\\00 |
| ---------------- | ----------------- | --------------------- |
| Simple Indexing  | 6.148648262023926 |                       |
| Partial Indexing | 6.488290309906006 |                       |

# Επίλογος

Θα συμπληρωθεί στη Φάση Β

# Αναφορές

1. [pip](https://pypi.org/project/pip/)
2. [nltk](https://www.nltk.org/)
